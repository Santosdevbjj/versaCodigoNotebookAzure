name: CD

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Databricks CLI and jq
      run: |
        python -m pip install --upgrade pip
        pip install databricks-cli
        sudo apt-get update
        sudo apt-get install -y jq

    - name: Validate Databricks secrets
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        if [ -z "${DATABRICKS_HOST}" ] || [ -z "${DATABRICKS_TOKEN}" ]; then
          echo "Erro: DATABRICKS_HOST ou DATABRICKS_TOKEN não configurados nos segredos do repositório."
          exit 1
        fi
        echo "Segredos do Databricks presentes. Prosseguindo com o deploy."

    - name: Deploy notebooks and libs to Databricks
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        echo "Iniciando o deploy de notebooks e libs..."
        # Importa o diretório de notebooks para o workspace do Databricks
        databricks workspace import_dir notebooks /Projects/versaCodigoNotebookAzure/notebooks --overwrite
        # Importa o diretório de bibliotecas (libs)
        databricks workspace import_dir libs /Projects/versaCodigoNotebookAzure/libs --overwrite
        echo "Deploy de notebooks e libs concluído."

    - name: Deploy cluster
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        set -e
        TEMPLATE=databricks/config/cluster_template.json
        if [ ! -f "$TEMPLATE" ]; then
          echo "Erro: arquivo $TEMPLATE não encontrado."
          exit 1
        fi

        CLUSTER_NAME=$(jq -r '.cluster_name' "$TEMPLATE")
        if [ -z "$CLUSTER_NAME" ] || [ "$CLUSTER_NAME" = "null" ]; then
          echo "Erro: cluster_name ausente em $TEMPLATE."
          exit 1
        fi

        CLUSTER_ID=$(databricks clusters list --output JSON 2>/dev/null | jq -r ".clusters[] | select(.cluster_name==\"$CLUSTER_NAME\") | .cluster_id")

        if [ -z "$CLUSTER_ID" ]; then
          echo "Cluster '$CLUSTER_NAME' não existe, criando..."
          databricks clusters create --json-file "$TEMPLATE"
        else
          echo "Cluster '$CLUSTER_NAME' já existe (ID: $CLUSTER_ID). Nenhuma atualização automática aplicada."
          # Observação: clusters edit requer 'cluster_id' no payload; se quiser editar, monte o JSON incluindo esse ID.
        fi

    - name: Deploy job pipeline
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        set -e
        JOB_NAME="job-pipeline-versaCodigo"
        JOB_SPEC=jobs/job_pipeline.json

        if [ ! -f "$JOB_SPEC" ]; then
          echo "Erro: arquivo $JOB_SPEC não encontrado."
          exit 1
        fi

        JOB_ID=$(databricks jobs list --output JSON 2>/dev/null | jq -r ".jobs[] | select(.settings.name==\"$JOB_NAME\") | .job_id")

        if [ -z "$JOB_ID" ]; then
          echo "Job '$JOB_NAME' não existe, criando..."
          databricks jobs create --json-file "$JOB_SPEC"
        else
          echo "Job '$JOB_NAME' já existe (ID: $JOB_ID). Atualizando..."
          # Cria payload para 'jobs update': { job_id, new_settings }
          jq --arg id "$JOB_ID" '. | {job_id: ($id | tonumber), new_settings: .}' "$JOB_SPEC" > job_update_payload.json
          databricks jobs update --json-file job_update_payload.json
          echo "Job '$JOB_NAME' atualizado com sucesso."
        fi
