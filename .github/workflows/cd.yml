name: CD

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Databricks CLI and JQ
      run: |
        python -m pip install --upgrade pip
        pip install databricks-cli jq

    - name: Deploy notebooks and libs to Databricks
      # Configura as credenciais via variáveis de ambiente, o método preferido.
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        echo "Iniciando o deploy de notebooks e libs..."
        # Importa o diretório de notebooks para o workspace do Databricks
        databricks workspace import_dir notebooks /Projects/versaCodigoNotebookAzure/notebooks --overwrite
        # Importa o diretório de bibliotecas (libs)
        databricks workspace import_dir libs /Projects/versaCodigoNotebookAzure/libs --overwrite
        echo "Deploy de notebooks e libs concluído."

    - name: Deploy cluster
      # Reutiliza as credenciais
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        CLUSTER_NAME=$(jq -r '.cluster_name' databricks/config/cluster_template.json)
        # Tenta encontrar o ID do cluster existente
        CLUSTER_ID=$(databricks clusters list --output JSON 2>/dev/null | jq -r ".clusters[] | select(.cluster_name==\"$CLUSTER_NAME\") | .cluster_id")

        if [ -z "$CLUSTER_ID" ]; then
          echo "Cluster '$CLUSTER_NAME' não existe, criando..."
          databricks clusters create --json-file databricks/config/cluster_template.json
        else
          echo "Cluster '$CLUSTER_NAME' já existe (ID: $CLUSTER_ID). Nenhuma atualização automática de configuração aplicada."
        fi

    - name: Deploy job pipeline
      # Reutiliza as credenciais
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        JOB_NAME="job-pipeline-versaCodigo"
        # Tenta encontrar o ID do job existente
        JOB_ID=$(databricks jobs list --output JSON 2>/dev/null | jq -r ".jobs[] | select(.settings.name==\"$JOB_NAME\") | .job_id")

        if [ -z "$JOB_ID" ]; then
          echo "Job '$JOB_NAME' não existe, criando..."
          # Assume que o jobs/job_pipeline.json é o arquivo para a criação
          databricks jobs create --json-file jobs/job_pipeline.json
        else
          echo "Job '$JOB_NAME' já existe (ID: $JOB_ID). Atualizando o job existente."
          # A maneira padrão de atualizar um job existente é usar jobs update
          # Nota: 'jobs update' espera um JSON com o campo 'job_id' e o campo 'new_settings'.
          # Uma abordagem mais simples é usar 'jobs reset' se o arquivo 'jobs/job_pipeline.json' contiver todas as configurações.
          # Vamos usar a lógica mais robusta de 'update' se o job_pipeline.json for o corpo completo da configuração:
          
          # 1. Cria um arquivo temporário com a estrutura correta para o update (ID + Settings)
          jq --arg id "$JOB_ID" '. | {job_id: ($id | tonumber), new_settings: .}' jobs/job_pipeline.json > job_update_payload.json
          
          # 2. Executa o update
          databricks jobs update --json-file job_update_payload.json
          echo "Job '$JOB_NAME' atualizado com sucesso."
        fi
